import { NextRequest, NextResponse } from 'next/server'
import Groq from 'groq-sdk'
import { FEATURE_FLAGS } from '@/lib/feature-flags'

interface NewsItem {
  title: string
  summary: string
  source: string
  category: string
}

interface TrendResult {
  trends: string
  keywords: string[]
}

// íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
const TREND_SYSTEM_PROMPT = `ë‹¹ì‹ ì€ **íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤.

**ë‹¹ì‹ ì˜ ì „ë¬¸ì„±:**
- ë‰´ìŠ¤ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ íŠ¸ë Œë“œë¥¼ ì‹ë³„í•˜ëŠ” ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€
- í‚¤ì›Œë“œ ë¹ˆë„ì™€ ì—°ê´€ì„±ì„ íŒŒì•…í•˜ì—¬ í˜„ì¬ íë¦„ì„ ë¶„ì„
- ë³µì¡í•œ ì •ë³´ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•˜ëŠ” ëŠ¥ë ¥
- ê°ê´€ì  ë°ì´í„° ê¸°ë°˜ì˜ íŠ¸ë Œë“œ ì˜ˆì¸¡

**ë‹¹ì‹ ì˜ ë¶„ì„ ë°©ì‹:**
- ë‰´ìŠ¤ ì œëª©ê³¼ ìš”ì•½ì—ì„œ ë°˜ë³µë˜ëŠ” í‚¤ì›Œë“œì™€ ì£¼ì œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤
- ì£¼ì œë³„ë¡œ ë‰´ìŠ¤ë¥¼ ê·¸ë£¹í™”í•˜ì—¬ í˜„ì¬ ê°€ì¥ ëœ¨ê±°ìš´ ì´ìŠˆë¥¼ íŒŒì•…í•©ë‹ˆë‹¤
- ê° íŠ¸ë Œë“œì˜ ê°•ë„ì™€ ë°©í–¥ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤
- ë…ìê°€ "ì§€ê¸ˆ ë¬´ì—‡ì´ í™”ì œì¸ì§€"ë¥¼ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•©ë‹ˆë‹¤

ë‹µë³€ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. ì‰¬ìš´ í•œê¸€ë¡œ ì‘ì„±í•˜ê³  í•œìì–´ëŠ” í”¼í•©ë‹ˆë‹¤.`

// íŠ¸ë Œë“œ ë¶„ì„ í”„ë¡¬í”„íŠ¸
function createTrendPrompt(newsText: string, newsCount: number): string {
  return `ë‹¤ìŒì€ í˜„ì¬ ì£¼ìš” ë‰´ìŠ¤ ${newsCount}ê°œì…ë‹ˆë‹¤. íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ í˜„ì¬ ë‰´ìŠ¤ íë¦„ê³¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

${newsText}

---

**ë¶„ì„ ìš”ì²­:**

1. **ğŸ“ˆ í˜„ì¬ í™”ì œ TOP 5**
   - í˜„ì¬ ê°€ì¥ ë§ì´ ì–¸ê¸‰ë˜ëŠ” ì£¼ì œ/ì´ìŠˆë¥¼ ìˆœìœ„ë¡œ ì •ë¦¬
   - ê° ì£¼ì œë³„ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì™€ í•µì‹¬ ë‚´ìš© ìš”ì•½
   - ì™œ ì´ ì£¼ì œê°€ í™”ì œì¸ì§€ ê°„ë‹¨íˆ ì„¤ëª…

2. **ğŸ”¥ íŠ¸ë Œë“œ ë¶„ì„**
   - **ìƒìŠ¹ íŠ¸ë Œë“œ**: ìµœê·¼ ê¸‰ë¶€ìƒí•˜ëŠ” ì´ìŠˆ/í‚¤ì›Œë“œ
   - **ì§€ì† íŠ¸ë Œë“œ**: ê¾¸ì¤€íˆ ì–¸ê¸‰ë˜ëŠ” ì´ìŠˆ
   - **ì£¼ëª©í•  ì‹ í˜¸**: ì•ìœ¼ë¡œ í™”ì œê°€ ë  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì´ìŠˆ

3. **ğŸ“Š í‚¤ì›Œë“œ ë§µ**
   - ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ 5ê°œ
   - ê° í‚¤ì›Œë“œê°€ ì–´ë–¤ ë§¥ë½ì—ì„œ ì‚¬ìš©ë˜ëŠ”ì§€

4. **ğŸ’¡ íŠ¸ë Œë“œ ìš”ì•½**
   - í•œ ì¤„ë¡œ ì •ë¦¬í•˜ëŠ” ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ íë¦„
   - ë…ìê°€ ì•Œì•„ì•¼ í•  í•µì‹¬ íŠ¸ë Œë“œ

**ì¤‘ìš” ì§€ì¹¨:**
- ì‰¬ìš´ í•œê¸€ ì‚¬ìš© (í•œìì–´ ëŒ€ì‹  ì¼ìƒ í‘œí˜„)
- ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì  ë¶„ì„
- ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°
- ë…ìê°€ "ì•„, ì§€ê¸ˆ ì´ê²Œ í™”ì œêµ¬ë‚˜!" í•˜ê³  ë°”ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON):**
{
  "trends": "ğŸ“ˆ **í˜„ì¬ í™”ì œ TOP 5**\\n\\n**1ìœ„. [ì£¼ì œëª…]** (ë‰´ìŠ¤ Nê±´)\\nâ€¢ í•µì‹¬ ë‚´ìš©...\\n\\n**2ìœ„. [ì£¼ì œëª…]** (ë‰´ìŠ¤ Nê±´)\\nâ€¢ í•µì‹¬ ë‚´ìš©...\\n\\nğŸ”¥ **íŠ¸ë Œë“œ ë¶„ì„**\\n\\n**ìƒìŠ¹ íŠ¸ë Œë“œ**\\nâ€¢ ...\\n\\n**ì§€ì† íŠ¸ë Œë“œ**\\nâ€¢ ...\\n\\n**ì£¼ëª©í•  ì‹ í˜¸**\\nâ€¢ ...\\n\\nğŸ“Š **í‚¤ì›Œë“œ ë§µ**\\nâ€¢ í‚¤ì›Œë“œ1: ë§¥ë½ ì„¤ëª…\\nâ€¢ í‚¤ì›Œë“œ2: ë§¥ë½ ì„¤ëª…\\n\\nğŸ’¡ **íŠ¸ë Œë“œ ìš”ì•½**\\nâ€¢ í•œ ì¤„ ì •ë¦¬...",
  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5"]
}`
}

// Groq API í˜¸ì¶œ í•¨ìˆ˜
async function generateWithGroq(prompt: string): Promise<TrendResult> {
  const groq = new Groq({
    apiKey: process.env.GROQ_API_KEY,
  })

  const response = await groq.chat.completions.create({
    model: 'llama-3.3-70b-versatile',
    messages: [
      { role: 'system', content: TREND_SYSTEM_PROMPT },
      { role: 'user', content: prompt },
    ],
    temperature: 0.4,
    max_tokens: 2500,
    response_format: { type: 'json_object' },
  })

  const content = response.choices[0]?.message?.content || ''

  const result = JSON.parse(content) as TrendResult
  if (!result.trends || !Array.isArray(result.keywords)) {
    throw new Error('Invalid response format')
  }
  result.keywords = result.keywords.slice(0, 5)

  return result
}

// Gemini API í˜¸ì¶œ í•¨ìˆ˜ (2nd í´ë°±)
async function generateWithGemini(prompt: string): Promise<TrendResult> {
  const baseUrl = 'https://generativelanguage.googleapis.com/v1beta'
  const model = process.env.GEMINI_MODEL || 'gemini-2.5-flash'

  const response = await fetch(
    `${baseUrl}/models/${model}:generateContent?key=${process.env.GEMINI_API_KEY}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: `${TREND_SYSTEM_PROMPT}\n\n${prompt}`,
              },
            ],
          },
        ],
        generationConfig: {
          temperature: 0.4,
          maxOutputTokens: 2500,
          responseMimeType: 'application/json',
        },
      }),
    }
  )

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}))
    throw new Error(`Gemini API error: ${response.status} - ${JSON.stringify(errorData)}`)
  }

  const data = await response.json()
  const content = data.candidates?.[0]?.content?.parts?.[0]?.text || ''

  // JSON ì¶”ì¶œ
  const jsonMatch = content.match(/\{[\s\S]*\}/)
  if (!jsonMatch) {
    throw new Error('No JSON found in response')
  }

  const result = JSON.parse(jsonMatch[0]) as TrendResult
  if (!result.trends || !Array.isArray(result.keywords)) {
    throw new Error('Invalid response format')
  }
  result.keywords = result.keywords.slice(0, 5)

  return result
}

// OpenRouter API í˜¸ì¶œ í•¨ìˆ˜ (3rd í´ë°±)
async function generateWithOpenRouter(prompt: string): Promise<TrendResult> {
  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
      'Content-Type': 'application/json',
      'HTTP-Referer': process.env.VERCEL_APP_URL || 'http://localhost:3000',
      'X-Title': 'KeyWordsNews',
    },
    body: JSON.stringify({
      model: process.env.OPENROUTER_MODEL || 'meta-llama/llama-3.1-70b-instruct:free',
      messages: [
        { role: 'system', content: TREND_SYSTEM_PROMPT },
        { role: 'user', content: prompt },
      ],
      temperature: 0.4,
      max_tokens: 2500,
    }),
  })

  if (!response.ok) {
    throw new Error(`OpenRouter API error: ${response.status}`)
  }

  const data = await response.json()
  const content = data.choices?.[0]?.message?.content || ''

  // JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬)
  const jsonMatch = content.match(/\{[\s\S]*\}/)
  if (!jsonMatch) {
    throw new Error('No JSON found in response')
  }

  const result = JSON.parse(jsonMatch[0]) as TrendResult
  if (!result.trends || !Array.isArray(result.keywords)) {
    throw new Error('Invalid response format')
  }
  result.keywords = result.keywords.slice(0, 5)

  return result
}

/**
 * POST /api/trend/now
 *
 * TrendNow API (ì¼ë°˜ JSON ì‘ë‹µ)
 * í˜„ì¬ ë¡œë“œëœ ë‰´ìŠ¤ë“¤ì˜ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
 * Fallback ìˆœì„œ: Groq -> Gemini -> OpenRouter
 *
 * @feature ENABLE_DAILY_INSIGHT
 */
export async function POST(request: NextRequest) {
  // Feature Flag ì²´í¬ (InsightNowì™€ ë™ì¼í•œ í”Œë˜ê·¸ ì‚¬ìš©)
  if (!FEATURE_FLAGS.ENABLE_DAILY_INSIGHT) {
    return NextResponse.json(
      { error: 'Trend analysis feature is disabled' },
      { status: 403 }
    )
  }

  try {
    const body = await request.json()
    const newsList: NewsItem[] = body.newsList

    // ìœ íš¨ì„± ê²€ì‚¬
    if (!Array.isArray(newsList) || newsList.length < 5) {
      return NextResponse.json(
        { error: 'ìµœì†Œ 5ê°œì˜ ë‰´ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 400 }
      )
    }

    console.log(`[TrendNow] News count: ${newsList.length}`)

    // ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    const newsText = newsList
      .map(
        (news, index) =>
          `[${index + 1}] [${news.source}] [${news.category}] ${news.title}\n   ìš”ì•½: ${news.summary || 'ì—†ìŒ'}`
      )
      .join('\n\n')

    const prompt = createTrendPrompt(newsText, newsList.length)

    let result: TrendResult
    let provider: string = 'groq'

    // 1ì°¨ ì‹œë„: Groq
    if (process.env.GROQ_API_KEY) {
      try {
        console.log('[TrendNow] Trying Groq...')
        result = await generateWithGroq(prompt)
        return NextResponse.json({
          success: true,
          data: result,
          provider,
        })
      } catch (error) {
        console.error('[TrendNow] Groq failed:', error)
        // í´ë°±ìœ¼ë¡œ ì§„í–‰
      }
    }

    // 2ì°¨ ì‹œë„: Gemini (2nd í´ë°±)
    if (process.env.GEMINI_API_KEY) {
      try {
        console.log('[TrendNow] Falling back to Gemini...')
        provider = 'gemini'
        result = await generateWithGemini(prompt)
        return NextResponse.json({
          success: true,
          data: result,
          provider,
        })
      } catch (error) {
        console.error('[TrendNow] Gemini failed:', error)
        // ë‹¤ìŒ í´ë°±ìœ¼ë¡œ ì§„í–‰
      }
    }

    // 3ì°¨ ì‹œë„: OpenRouter (3rd í´ë°±)
    if (process.env.OPENROUTER_API_KEY) {
      try {
        console.log('[TrendNow] Falling back to OpenRouter...')
        provider = 'openrouter'
        result = await generateWithOpenRouter(prompt)
        return NextResponse.json({
          success: true,
          data: result,
          provider,
        })
      } catch (error) {
        console.error('[TrendNow] OpenRouter failed:', error)
        const errorMessage = error instanceof Error ? error.message : 'Unknown error'
        return NextResponse.json(
          { error: `ëª¨ë“  AI í”„ë¡œë°”ì´ë” ì‹¤íŒ¨: ${errorMessage}` },
          { status: 500 }
        )
      }
    }

    // ëª¨ë“  í”„ë¡œë°”ì´ë” ì‚¬ìš© ë¶ˆê°€
    return NextResponse.json(
      { error: 'AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GROQ_API_KEY, GEMINI_API_KEY ë˜ëŠ” OPENROUTER_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.' },
      { status: 500 }
    )
  } catch (error) {
    console.error('[TrendNow API Error]', error)
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    )
  }
}
